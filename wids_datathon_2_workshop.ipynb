{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956d3a36-3445-4931-baf2-7bb035612665",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Datathon challenge task\n",
    "Predict the duration of time it takes for patients to receive metastatic cancer diagnosis.\n",
    "\n",
    "### EDA Techniques\n",
    "- Analysis\n",
    "    - Load data\n",
    "    - Understand the data:\n",
    "        - Categorize the types of features\n",
    "        - Data shape, types, missing (null) values, unique values\n",
    "        - Categorical vs numeric data, and which of the categorical data is ordinal (has an order)\n",
    "        - Statistical analysis\n",
    "        - Visualizations\n",
    "            - Univariate\n",
    "            - Bivariate\n",
    "            - Multivariate\n",
    "    - Feature correlations\n",
    "- Cleaning\n",
    "    - Removing features\n",
    "    - Handling missing data\n",
    "    - Encoding categorical variables\n",
    "- Feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b875cc-3d83-4511-b784-24fc2e4232d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f086ee9-d403-4098-8971-6c9b39d3a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea50d42-849b-4722-80fd-98c698f6027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, RobustScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13601f23-cb31-42ef-9c0a-1f28e7a22059",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068432f-be12-4e19-a4bf-d50f00657c65",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee57ba-dd31-4454-a8b0-88346a67f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .csv data as dataframes and make patient_id the index\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv', index_col='patient_id')\n",
    "df_test = pd.read_csv('data/test.csv', index_col='patient_id')\n",
    "\n",
    "# Look at the first few rows of data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12b453-b14c-4d72-843a-722bf7cdf199",
   "metadata": {},
   "source": [
    "## Understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f1bb1-40ac-49bb-a6a3-e3fb8c8f8ff0",
   "metadata": {},
   "source": [
    "In order to work with the data we need to know the different data types. Following are some basic types:\n",
    "\n",
    "1. **Numerical**: Data represented by numbers and can be measured or expressed in number format.\n",
    "   \n",
    "       - Discrete Data: Data that can only take specific numerical values within a certain range, typically integers.\n",
    "   \n",
    "       - Continuous Data: Data that can take any value within a certain range and can be measured at any point on a scale.\n",
    "   \n",
    "       - Time Series Data: Data collected or recorded at regular time intervals, often used for analyzing trends over time.\n",
    "   \n",
    "   \n",
    "3. **Categorical Data**: Data that represents categories or labels and cannot be measured on a numerical scale.\n",
    "   \n",
    "       - Ordinal Data: Data with categories that have a specific order or ranking.\n",
    "   \n",
    "       - Nominal Data: A type of categorical data where categories are merely labels without any inherent order.\n",
    "   \n",
    "   \n",
    "5. **Others**: Spatial, unstructured free text, video, images, graph data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac9462-e712-4dd0-b9d5-79b4e00156bb",
   "metadata": {},
   "source": [
    "### Categorize the types of features\n",
    "\n",
    "Read the [data descriptions](https://www.kaggle.com/competitions/widsdatathon2024-challenge2/data) on Kaggle.\n",
    "\n",
    "**Patient characteristics:** patient_race, payer_type, patient_age, patient_gender, bmi\n",
    "\n",
    "**Patient location:** patient_state, patient_zip3, region, division\n",
    "\n",
    "**Breast cancer diagnosis information:** breast_cancer_diagnosis_code, breast_cancer_diagnosis_desc, metastatic_cancer_diagnosis_code, \n",
    "    metastatic_first_novel_treatment, metastatic_first_novel_treatment_type\n",
    "\n",
    "**Geo (zip-code level) demographic data:** Many! (population, income, education, rent, race, poverty etc)\n",
    "\n",
    "**Climate data:** 72 columns showing the zip 3 Monthly Average Temperature for the patientâ€™s zip 3 and month referenced\n",
    "\n",
    "**Target variable:** metastatic_diagnosis_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e278e-fe09-4f81-91de-8863da7d1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that shows the data dimensions (# rows and columns), total # NA values, and data types, \n",
    "# number of distinct NA (null) values for each column (feature)\n",
    "\n",
    "def initial_eda(df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        total_na = df.isna().sum().sum()\n",
    "        print(\"Dimensions : %d rows, %d columns\" % (df.shape[0], df.shape[1]))\n",
    "        print(\"Total NA Values : %d \" % (total_na))\n",
    "        print(\"%38s %10s     %10s %10s\" % (\"Column Name\", \"Data Type\", \"#Distinct\", \"NaN Values\"))\n",
    "        col_name = df.columns\n",
    "        dtyp = df.dtypes\n",
    "        uniq = df.nunique()\n",
    "        na_val = df.isna().sum()\n",
    "        for i in range(len(df.columns)):\n",
    "            print(\"%38s %10s   %10s %10s\" % (col_name[i], dtyp[i], uniq[i], na_val[i]))\n",
    "        \n",
    "    else:\n",
    "        print(\"Expect a DataFrame but got a %15s\" % (type(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9026876-2cf9-46ac-8588-6ab1dc02c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function on our training data\n",
    "\n",
    "initial_eda(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680355a-533d-4ace-8ece-6c924942f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function on our testing data\n",
    "\n",
    "initial_eda(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792931b-f5be-45c7-a55d-7a90f6120f37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Observations\n",
    "\n",
    "**Data types**\n",
    "\n",
    "- 11 object types in train and test - these are categorical features\n",
    "    - None of these seem to be ordinal\n",
    "\n",
    "- 3 integer types in train, 2 in test - zip, age, and the target variable (metastatic_diagnosis_period)\n",
    "\n",
    "- The rest of the features are floats\n",
    "\n",
    "**# distinct values**\n",
    "\n",
    "- Only 1 distinct value for patient_gender (female) in train and test data, so we can drop this feature\n",
    "\n",
    "- Only 1 distinct value for metastatic_first_novel_treatment_type in train and test data, and only 11 rows contain a value in train and 7 in test, so we can drop this feature\n",
    "\n",
    "- Only 2 distinct values for metastatic_first_novel_treatment in train and test data, and only 11 rows contain a value in train and 7 in test, so we can probably drop this feature, but look for any strong correlation with the target feature\n",
    "\n",
    "- patient_zip3 and population have the same number of unique values in train (751) and test (669), so do we need them both? \n",
    "Population is a size, so it might be important. Is zip random? How strong is the correlation with the target variable?\n",
    "\n",
    "**NaN values - need to start thinking about how to handle these**\n",
    "\n",
    "- patient_race: ~half are missing in train and test\n",
    "\n",
    "- payer_type: 13-14% are missing in train and test\n",
    "\n",
    "- bmi: 69-70% are missing in train and test\n",
    "\n",
    "- metastatic_cancer_diagnosis_code and metastatic_first_novel_treatment_type: almost all are missing\n",
    "\n",
    "- Several features (23) are missing 5 values in the train data but none of those are missing in the test data. Are the 5 missing values for\n",
    "each feature in the same row? If so, can we just drop those rows? (Yes, all are in the same rows and they are in the same zip, and those\n",
    "are the only 5 records for that zip, but that zip is not in the test data, so we can probably drop them.)\n",
    "\n",
    "- Avg temps: Missing 0-180 in train and 0-95 in test. The 180/95 are in Apr-14 and are all in NY (6 zips) or ID (1 zip) in both train\n",
    "and test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af5510-8f18-4330-a993-f127232669a5",
   "metadata": {},
   "source": [
    "### Drop features and observations that logically add no value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430d35d-ed87-41d2-91b3-25b6763b4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features\n",
    "\n",
    "# Only one value for patient_gender\n",
    "# Only one value for metastatic_first_novel_treatment_type and two values for metastatic_first_novel_treatment, \n",
    "# and there are only 11 non-null rows in the train data, and 7 non-null in the test data\n",
    "\n",
    "drop_features = [\n",
    "                    'metastatic_first_novel_treatment',         # rarely filled in\n",
    "                    'metastatic_first_novel_treatment_type',    # rarely filled in\n",
    "                    'patient_gender',                           # always the same value\n",
    "                   ]\n",
    "\n",
    "# Always perform the same actions on train and test data\n",
    "df_train = df_train.drop(drop_features, axis=1)\n",
    "df_test = df_test.drop(drop_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051972c-538c-48dc-95f7-1dad5253141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows\n",
    "\n",
    "# Drop the 5 rows that have 23 missing features all from the same zip; that zip is not present in the test set\n",
    "mask = (df_train['patient_zip3'] == 772)\n",
    "df_train = df_train.drop(df_train[df_train['patient_zip3'] == 772].index)\n",
    "\n",
    "# Check the shape (originally we had 13173 rows)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8dd47-365b-4ab9-8d94-b618aba613f3",
   "metadata": {},
   "source": [
    "### Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257c658-8854-49ab-aeb4-eae6b25deca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not truncate\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa0530-3ca8-400d-bb2f-617433cad8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a8af6-90b2-46dc-83d2-b8f3046cc959",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "**patient_zip3** max in test is different than train so we know there are values in test that are not in train (and probably vice versa)\n",
    "\n",
    "**patient_age** range from 18-91\n",
    "\n",
    "**bmi** max is 97 in train but only 43.7 in test! Looking closer, there is one 90 and one 97 in the train data, which are anomalies,\n",
    "perhaps we remove those rows\n",
    "\n",
    "**target variable** min=0, max=365, mean=96.5, std=109, count of 0=3126, count >= 350=224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3386b-34f9-4011-a507-4d85de898203",
   "metadata": {},
   "source": [
    "#### Distribution plots of the variables are a good way to understand differences in data representation. Ideally we want the train and test data sets to have similar distributions as they both represent a random sample of the true population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f3511-bb09-42ec-a235-120812573e69",
   "metadata": {},
   "source": [
    "### Categorical vs numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a3602-56a5-4825-8c50-3c78cae06226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for the categorical and numeric features of df_train (df_test will be the same except the target col)\n",
    "# Also create a variable for the target column\n",
    "\n",
    "cat_cols=df_train.select_dtypes(include=['object']).columns\n",
    "num_cols = df_train.select_dtypes(include=np.number).columns.tolist()\n",
    "target_col = 'metastatic_diagnosis_period'\n",
    "print(\"Categorical Variables:\")\n",
    "print(cat_cols)\n",
    "print(\"Numerical Variables:\")\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1fa83-7f4f-4643-9416-bc18e288d3d4",
   "metadata": {},
   "source": [
    "### Compare unique values in df_train and df_test\n",
    "\n",
    "Which features are present in the training data but not in the test data, and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef44d7c-6dee-468a-8da0-fe8506fe520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the columns of df_train\n",
    "for col in df_train.columns:\n",
    "    # Check if the column exists in df_test\n",
    "    if col in df_test.columns:\n",
    "        # Get the unique values of col in df_train\n",
    "        unique_values_train = df_train[col].unique()\n",
    "        # Get the unique values of col in df_test\n",
    "        unique_values_test = df_test[col].unique()\n",
    "        # Find the differences between the two sets\n",
    "        differences = set(unique_values_train) - set(unique_values_test)\n",
    "        diff_count = len(differences)\n",
    "        if len(differences) > 0:\n",
    "            print(f\"{col} has the following unique values that are not present in the test dataset: {differences}\")\n",
    "            print(f\"{col} has the following number of differences: {diff_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f2f01-0881-4a63-93c5-617133ad898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the columns of df_test\n",
    "for col in df_test.columns:\n",
    "    # Check if the column exists in df_test\n",
    "    if col in df_train.columns:\n",
    "        # Get the unique values of col in df_train\n",
    "        unique_values_test = df_test[col].unique()\n",
    "        # Get the unique values of col in df_test\n",
    "        unique_values_train = df_train[col].unique()\n",
    "        # Find the differences between the two sets\n",
    "        differences = set(unique_values_test) - set(unique_values_train)\n",
    "        diff_count = len(differences)\n",
    "        if len(differences) > 0:\n",
    "            print(f\"{col} has the following unique values that are not present in the train dataset: {differences}\")\n",
    "            print(f\"{col} has the following number of differences: {diff_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97820c9-4d76-4f1c-8c8d-f41ba2ffa78c",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "**patient_race, payer_type, patient_state, Region, Division, patient_age** Same values in train and test\n",
    "\n",
    "**patient_zip3 and population** Train has 93 zips/populations not in test, test has 12 zips/populations not in train\n",
    "\n",
    "**breast_cancer_diagnosis_code** Train has 7 values not in test (but just 1 or a few occurences of each), test has 1 value not in train (but only 1 occurrence of it)\n",
    "\n",
    "**metastatic_cancer_diagnosis_code** Train has 7 values not in test (but just 1 or a few occurences of each), test has 2 values not in train (but only 1 occurrence of each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e960c8-1c98-4bac-8fe2-03d93ab5d8be",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Categorical variables can be visualized using a Count plot, Bar Chart, Pie Plot, etc.\n",
    "\n",
    "Numerical Variables can be visualized using Histogram, Box Plot, Density Plot, etc.\n",
    "\n",
    "Box Plot: Also marks the outliers. the first box edge or line represents 25%(first quartile) of the data is below it. The middle line is the median, the third the end of the box represents 75%(third quartiles) of the data values. Q3-Q1 is known as the Interquartile range (IQR) and values lower than 1.5 times the Q1 and values higher than 1.5 times the Q3 are typically considered outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a549ebe-6082-4dc4-b3a2-b01a3ac9dc70",
   "metadata": {},
   "source": [
    "#### Univariate analysis\n",
    "\n",
    "Univariate analysis examines the distribution of a single variable in isolation, without considering its relationship with other variables. It helps to understand the characteristics and patterns within individual variables, including measures of central tendency, dispersion, and shape of the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c53f4-c1ad-400e-bee0-87e782c28042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and box plot of numerical data for df_train\n",
    "\n",
    "for col in num_cols:\n",
    "    print(col)\n",
    "    print('Skew :', round(df_train[col].skew(), 2))\n",
    "    plt.figure(figsize = (15, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_train[col].hist(grid=False)\n",
    "    plt.ylabel('count')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df_train[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428d3bc-50ef-4a5a-9a80-6ae07f53d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram and box plot of numerical data for df_test\n",
    "\n",
    "for col in num_cols:\n",
    "    print(col)\n",
    "    print('Skew :', round(df_test[col].skew(), 2))\n",
    "    plt.figure(figsize = (15, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_test[col].hist(grid=False)\n",
    "    plt.ylabel('count')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df_test[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb2270-70ea-45c3-9f9b-37cb60d13f08",
   "metadata": {},
   "source": [
    "#### Observations of data\n",
    "\n",
    "**bmi** 3 major outliers for train data, perhaps we drop those rows\n",
    "\n",
    "**density** is quite skewed and has many outliers, but same for both data sets\n",
    "\n",
    "**metastatic_diagnosis_period** Median is less than 50 days, has a right positive skew\n",
    "\n",
    "**age_over_80** Out of proportion between the data sets based on histograms (box plots are very similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92225c3-e249-4987-b438-9ff5eb9a2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81faeae7-4e0f-49a1-a9e4-79408bcb8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot of categorical data for df_train\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize = (18, 18))\n",
    "fig.suptitle('Bar plot for all categorical variables in the dataset')\n",
    "sns.countplot(ax = axes[0, 0], x = 'patient_race', data = df_train, color = 'blue', \n",
    "              order = df_train['patient_race'].value_counts().index);\n",
    "sns.countplot(ax = axes[0, 1], x = 'payer_type', data = df_train, color = 'blue', \n",
    "              order = df_train['payer_type'].value_counts().index);\n",
    "sns.countplot(ax = axes[1, 0], x = 'patient_state', data = df_train, color = 'blue', \n",
    "              order = df_train['patient_state'].value_counts().index);\n",
    "sns.countplot(ax = axes[1, 1], x = 'Region', data = df_train, color = 'blue', \n",
    "              order = df_train['Region'].value_counts().index);\n",
    "sns.countplot(ax = axes[2, 0], x = 'Division', data = df_train, color = 'blue', \n",
    "              order = df_train['Division'].value_counts().index);\n",
    "sns.countplot(ax = axes[2, 1], x = 'breast_cancer_diagnosis_code', data = df_train, color = 'blue', \n",
    "              order = df_train['breast_cancer_diagnosis_code'].value_counts().index);\n",
    "sns.countplot(ax = axes[3, 0], x = 'breast_cancer_diagnosis_desc', data = df_train, color = 'blue', \n",
    "              order = df_train['breast_cancer_diagnosis_desc'].value_counts().index);\n",
    "sns.countplot(ax = axes[3, 1], x = 'metastatic_cancer_diagnosis_code', data = df_train, color = 'blue', \n",
    "              order = df_train['metastatic_cancer_diagnosis_code'].value_counts().index);\n",
    "\n",
    "axes[1][0].tick_params(labelrotation=90);\n",
    "axes[2][0].tick_params(labelrotation=45);\n",
    "axes[2][1].tick_params(labelrotation=90);\n",
    "axes[3][0].tick_params(labelrotation=90);\n",
    "axes[3][1].tick_params(labelrotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a9a81-eb9f-4c43-9e43-e6fd3b5d88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot of categorical data for df_test\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize = (18, 18))\n",
    "fig.suptitle('Bar plot for all categorical variables in the dataset')\n",
    "sns.countplot(ax = axes[0, 0], x = 'patient_race', data = df_test, color = 'blue', \n",
    "              order = df_test['patient_race'].value_counts().index);\n",
    "sns.countplot(ax = axes[0, 1], x = 'payer_type', data = df_test, color = 'blue', \n",
    "              order = df_test['payer_type'].value_counts().index);\n",
    "sns.countplot(ax = axes[1, 0], x = 'patient_state', data = df_test, color = 'blue', \n",
    "              order = df_test['patient_state'].value_counts().index);\n",
    "sns.countplot(ax = axes[1, 1], x = 'Region', data = df_test, color = 'blue', \n",
    "              order = df_test['Region'].value_counts().index);\n",
    "sns.countplot(ax = axes[2, 0], x = 'Division', data = df_test, color = 'blue', \n",
    "              order = df_test['Division'].value_counts().index);\n",
    "sns.countplot(ax = axes[2, 1], x = 'breast_cancer_diagnosis_code', data = df_test, color = 'blue', \n",
    "              order = df_test['breast_cancer_diagnosis_code'].value_counts().index);\n",
    "sns.countplot(ax = axes[3, 0], x = 'breast_cancer_diagnosis_desc', data = df_test, color = 'blue', \n",
    "              order = df_test['breast_cancer_diagnosis_desc'].value_counts().index);\n",
    "sns.countplot(ax = axes[3, 1], x = 'metastatic_cancer_diagnosis_code', data = df_test, color = 'blue', \n",
    "              order = df_test['metastatic_cancer_diagnosis_code'].value_counts().index);\n",
    "\n",
    "axes[1][0].tick_params(labelrotation=90);\n",
    "axes[2][0].tick_params(labelrotation=45);\n",
    "axes[2][1].tick_params(labelrotation=90);\n",
    "axes[3][0].tick_params(labelrotation=90);\n",
    "axes[3][1].tick_params(labelrotation=90);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3a829-4343-4b66-bae9-635f3a9082bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group the data by breast_cancer_diagnosis_code and calculate the mean metastatic_diagnosis_period\n",
    "\n",
    "grouped_data = df_train.groupby(\"breast_cancer_diagnosis_code\").mean()[\"metastatic_diagnosis_period\"]\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee19fe-6441-41bb-a806-6c06c6934090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart of the mean metastatic_diagnosis_period for each breast_cancer_diagnosis_code\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(range(len(grouped_data)), grouped_data)\n",
    "plt.xticks(range(len(grouped_data)), grouped_data.index, rotation=90)\n",
    "plt.xlabel(\"Diagnosis Code\")\n",
    "plt.ylabel(\"Mean Metastatic Diagnosis Period\")\n",
    "plt.title(\"Mean Metastatic Diagnosis Period for Each Breast Cancer Diagnosis Code\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4332da-e93d-46d0-b1eb-81207f881280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by metastatic_cancer_diagnosis_code and calculate the mean metastatic_diagnosis_period\n",
    "\n",
    "grouped_data = df_train.groupby(\"metastatic_cancer_diagnosis_code\").mean()[\"metastatic_diagnosis_period\"]\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f728c0-a6b4-4f88-ba47-87ac4a9aa582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart of the mean metastatic_diagnosis_period for each metastatic_cancer_diagnosis_code\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(range(len(grouped_data)), grouped_data)\n",
    "plt.xticks(range(len(grouped_data)), grouped_data.index, rotation=90)\n",
    "plt.xlabel(\"Diagnosis Code\")\n",
    "plt.ylabel(\"Mean Metastatic Diagnosis Period\")\n",
    "plt.title(\"Mean Metastatic Diagnosis Period for Each Metastatic Cancer Diagnosis Code\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7eb348-8afe-4713-8ecc-8da16f861327",
   "metadata": {},
   "source": [
    "## Visualizations - bivariate analysis\n",
    "\n",
    "Bivariate analysis explores the relationship between two variables to understand how they interact or influence each other. This highlights any dependencies or trends between two variables.\n",
    "\n",
    "Cons: Often too simplistic and ignores potential confounding factors or nonlinear associations. Does not capture complex relations.\n",
    "\n",
    "Note for other methods of analysis:\n",
    "\n",
    "1. Multivariate Analysis: Examines the relationship between multiple independent variables and a single dependent variable.\n",
    "2. Factor Analysis: Explores underlying factors that explain the correlations among observed variables.\n",
    "3. Cluster analysis: Identifies groups or clusters of observations with similar characteristics based on multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468411eb-8324-49e2-ae4d-f930265afa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['breast_cancer_diagnosis_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e29367-f5e1-4547-b0c2-5d6b50564358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bar plot to show the relationship between Categorical variables and the target continuous variables \n",
    "\n",
    "fig, axarr = plt.subplots(4, 2, figsize=(18, 24))\n",
    "df_train.groupby('patient_race')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[0][0], fontsize=12)\n",
    "axarr[0][0].set_title(\"patient_race Vs target\", fontsize=18)\n",
    "df_train.groupby('payer_type')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[0][1], fontsize=12)\n",
    "axarr[0][1].set_title(\"payer_type Vs target\", fontsize=18)\n",
    "df_train.groupby('patient_state')[target_col].mean().sort_values(ascending=False).head(20).plot.bar(ax=axarr[1][0], fontsize=12)\n",
    "axarr[1][0].set_title(\"patient_state top 10\", fontsize=18)\n",
    "df_train.groupby('Region')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[1][1], fontsize=12)\n",
    "axarr[1][1].set_title(\"Region Vs target\", fontsize=18)\n",
    "df_train.groupby('Division')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[2][0], fontsize=12)\n",
    "axarr[2][0].set_title(\"Division Vs target\", fontsize=18)\n",
    "df_train.groupby('breast_cancer_diagnosis_code')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[2][1], fontsize=12)\n",
    "axarr[2][1].set_title(\"breast_cancer_diagnosis_code Vs target\", fontsize=18)\n",
    "df_train.groupby('breast_cancer_diagnosis_desc')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[3][0], fontsize=12)\n",
    "axarr[3][0].set_title(\"breast_cancer_diagnosis_desc Vs target\", fontsize=18)\n",
    "df_train.groupby('metastatic_cancer_diagnosis_code')[target_col].mean().sort_values(ascending=False).plot.bar(ax=axarr[3][1], fontsize=12)\n",
    "axarr[3][1].set_title(\"metastatic_cancer_diagnosis_code Vs target\", fontsize=18)\n",
    "plt.subplots_adjust(hspace=1.0)\n",
    "plt.subplots_adjust(wspace=.5)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5f1bf-a59c-461f-981d-39d623b2f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "df_train.groupby('patient_state')[target_col].mean().sort_values(ascending=False).plot.bar(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e4943-0740-4eb8-8e7b-1d8aeaf4a0c8",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804dbd65-8659-4ae6-b91a-079e24fa69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep - replace categorical column nulls with 'unknown'\n",
    "\n",
    "for column in cat_cols:\n",
    "    df_train[column] = df_train[column].mask(df_train[column].isnull(), 'unknown')\n",
    "    df_test[column] = df_test[column].mask(df_test[column].isnull(), 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738dffd-ba32-42b5-bd87-8c022974bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target from num_cols\n",
    "\n",
    "num_cols.remove(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1119b-c732-4e94-8e83-19fbf875fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep - remaining nulls are in numeric columns - convert them to mean values from df_train\n",
    "# (since df_train has more data and will likely have a more representative mean value than df_test)\n",
    "\n",
    "for column in num_cols:\n",
    "    mean_value = df_train[column].mean()\n",
    "    df_train[column] = df_train[column].mask(df_train[column].isnull(), mean_value)\n",
    "    df_test[column] = df_test[column].mask(df_test[column].isnull(), mean_value) \n",
    "\n",
    "df_train.head()\n",
    "\n",
    "# Alternatively, assign large numbers to nulls in numeric columns\n",
    "'''\n",
    "for column in num_cols:\n",
    "    replacement_value = 1000000\n",
    "    df_train[column] = df_train[column].mask(df_train[column].isnull(), replacement_value)\n",
    "    df_test[column] = df_test[column].mask(df_test[column].isnull(), replacement_value) \n",
    "\n",
    "df_train.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130e371-29f8-43bb-933e-7dfd7c3e1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numbers using LabelEncoder()\n",
    "\n",
    "for column in cat_cols:\n",
    "    df_combined = pd.concat([df_train, df_test], axis=0)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_combined[column])\n",
    "    df_train[column] = le.transform(df_train[column])\n",
    "    df_test[column] = le.transform(df_test[column])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e395cea-e3eb-496c-b8f0-dfb281caa855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9551627-6024-47c7-ab4b-3554f8e90903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c884728-49b5-4c87-95df-3d26cd0f8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb94708-0fe0-4851-99a8-e7d292f18835",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Correlation coefficients quantify the strength and direction of the linear relationship between two variables. Positive correlations indicate that as one variable increases, the other tends to increase as well, while negative correlations suggest that as one variable increases, the other tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5b804-3824-4056-a7df-cd5fe47ab601",
   "metadata": {},
   "source": [
    "### Correlation EDA by feature category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec000ee-7b83-433a-aaf6-abf0dda1c753",
   "metadata": {},
   "source": [
    "Since there are so many features, a heatmap of all features is not comprehensible. So let us break down the features in a way that makes sense for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22543abb-6197-4847-8fb9-a10fe7f34cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_demographics = [\n",
    "    \"patient_race\",\n",
    "    \"patient_state\",\n",
    "    \"patient_zip3\",\n",
    "    \"patient_age\",\n",
    "    \"bmi\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "diagnosis_codes = [\n",
    "    \"breast_cancer_diagnosis_code\",\n",
    "    \"metastatic_cancer_diagnosis_code\"\n",
    "]\n",
    "\n",
    "treatment = [\n",
    "    \"metastatic_first_novel_treatment\",\n",
    "    \"metastatic_first_novel_treatment_type\"\n",
    "]\n",
    "\n",
    "demographics_by_zip_code = [\n",
    "    \"population\",\n",
    "    \"density\",\n",
    "    \"age_median\",\n",
    "    \"male\",\n",
    "    \"female\",\n",
    "    \"married\",\n",
    "    \"family_size\",\n",
    "    \"income_household_median\",\n",
    "    \"income_household_six_figure\",\n",
    "    \"home_ownership\",\n",
    "    \"housing_units\",\n",
    "    \"home_value\",\n",
    "    \"rent_median\",\n",
    "    \"education_college_or_above\",\n",
    "    \"labor_force_participation\",\n",
    "    \"unemployment_rate\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "race_and_ethnicity = [\n",
    "    \"race_white\",\n",
    "    \"race_black\",\n",
    "    \"race_asian\",\n",
    "    \"race_native\",\n",
    "    \"race_pacific\",\n",
    "    \"race_other\",\n",
    "    \"race_multiple\",\n",
    "    \"hispanic\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "age_groups = [\n",
    "    \"age_under_10\",\n",
    "    \"age_10_to_19\",\n",
    "    \"age_20s\",\n",
    "    \"age_30s\",\n",
    "    \"age_40s\",\n",
    "    \"age_50s\",\n",
    "    \"age_60s\",\n",
    "    \"age_70s\",\n",
    "    \"age_over_80\", \n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "marital_status = [\n",
    "    \"divorced\",\n",
    "    \"never_married\",\n",
    "    \"widowed\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "income = [\n",
    "    \"family_dual_income\",  # Create this feature based on family_dual_income\n",
    "    \"income_household_under_5\",\n",
    "    \"income_household_5_to_10\",\n",
    "    \"income_household_10_to_15\", \n",
    "    \"income_household_15_to_20\",\n",
    "    \"income_household_20_to_25\",\n",
    "    \"income_household_25_to_35\",\n",
    "    \"income_household_35_to_50\",\n",
    "    \"income_household_50_to_75\",\n",
    "    \"income_household_75_to_100\",\n",
    "    \"income_household_100_to_150\",\n",
    "    \"income_household_150_over\", \n",
    "    \"income_individual_median\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "socioeconomic_factors = [\n",
    "    \"poverty\",\n",
    "    \"rent_burden\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "education = [\n",
    "    \"education_less_highschool\",\n",
    "    \"education_highschool\",\n",
    "    \"education_some_college\",\n",
    "    \"education_bachelors\",\n",
    "    \"education_graduate\",\n",
    "    \"education_stem_degree\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "employment = [\n",
    "    \"self_employed\",\n",
    "    \"farmer\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "other = [\n",
    "    \"disabled\",\n",
    "    \"limited_english\",\n",
    "    \"commute_time\",\n",
    "    \"health_uninsured\",\n",
    "    \"veteran\",\n",
    "    \"metastatic_diagnosis_period\"\n",
    "]\n",
    "\n",
    "# Time-based averages (needs further handling based on your approach)\n",
    "time_based_averages = [\n",
    "    'Average of Jan-13', 'Average of Feb-13', 'Average of Mar-13', 'Average of Apr-13', 'Average of May-13', 'Average of Jun-13', 'Average of Jul-13', 'Average of Aug-13', 'Average of Sep-13', 'Average of Oct-13', 'Average of Nov-13', 'Average of Dec-13', 'Average of Jan-14', 'Average of Feb-14', 'Average of Mar-14', 'Average of Apr-14', 'Average of May-14', 'Average of Jun-14', 'Average of Jul-14', 'Average of Aug-14', 'Average of Sep-14', 'Average of Oct-14', 'Average of Nov-14', 'Average of Dec-14', 'Average of Jan-15', 'Average of Feb-15', 'Average of Mar-15', 'Average of Apr-15', 'Average of May-15', 'Average of Jun-15', 'Average of Jul-15', 'Average of Aug-15', 'Average of Sep-15', 'Average of Oct-15', 'Average of Nov-15', 'Average of Dec-15', 'Average of Jan-16', 'Average of Feb-16', 'Average of Mar-16', 'Average of Apr-16', 'Average of May-16', 'Average of Jun-16', 'Average of Jul-16', 'Average of Aug-16', 'Average of Sep-16', 'Average of Oct-16', 'Average of Nov-16', 'Average of Dec-16', 'Average of Jan-17', 'Average of Feb-17', 'Average of Mar-17', 'Average of Apr-17', 'Average of May-17', 'Average of Jun-17', 'Average of Jul-17', 'Average of Aug-17', 'Average of Sep-17', 'Average of Oct-17', 'Average of Nov-17', 'Average of Dec-17', 'Average of Jan-18', 'Average of Feb-18', 'Average of Mar-18', 'Average of Apr-18', 'Average of May-18', 'Average of Jun-18', 'Average of Jul-18', 'Average of Aug-18', 'Average of Sep-18', 'Average of Oct-18', 'Average of Nov-18', 'Average of Dec-18',\n",
    "    'metastatic_diagnosis_period'\n",
    "]  # List to store features based on your chosen approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96edab-8100-41f2-8865-da54a1d117d9",
   "metadata": {},
   "source": [
    "#### Patient Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210143bd-4689-4c68-894a-53afa88f7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[patient_demographics].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c94ff-f80d-47e5-bf5e-7024fa8640b1",
   "metadata": {},
   "source": [
    "####  Demographics by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0fc90-529e-4aa5-b66e-85cc0c26d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[demographics_by_zip_code].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d66e34-f6f1-42b2-8413-46f05889a782",
   "metadata": {},
   "source": [
    "#### race_and_ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf39b23-2ec0-4b53-bfaf-318ee8d6105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[race_and_ethnicity].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c9723-59b9-4e1b-8faf-c145e9aabba7",
   "metadata": {},
   "source": [
    "#### Age group correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5210cb3-b917-4c2b-9a0c-47388aeb4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[age_groups].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816db8f-32db-4ff4-ad7f-6de4df3714e0",
   "metadata": {},
   "source": [
    "####   marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244bdce-a658-447b-b2f8-fde89ed1be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[marital_status].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f49d8-25d5-4483-8ba1-33ac364e47c8",
   "metadata": {},
   "source": [
    "### Income Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81ac83-830c-4773-a6ec-aff9250cc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[income].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ed2ef-24db-4f7c-9bfe-af6cd48b3f63",
   "metadata": {},
   "source": [
    "#### Socio-economic factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a1996-c46a-4377-b403-4c28555d04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[socioeconomic_factors].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9325be-a3e6-4543-8cea-264fe6cafc58",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f1731-fc69-4748-9d28-ed2171806c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[education].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f383ee-a91a-4b40-a92a-d6039fb2d089",
   "metadata": {},
   "source": [
    "#### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae716b5-dca0-47db-b548-b6535c7dbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[employment].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3412943-7b7f-4006-b646-eaab05c877a9",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac464d-6cc7-42dc-a01c-f8a340d49ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "correlation_matrix = df_train[other].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Adjust 'cmap' for color scheme\n",
    "plt.title('Correlation Matrix (Features vs. Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fff4dd-6485-49c1-b2f5-64498e02395c",
   "metadata": {},
   "source": [
    "### Correlation between each features and the target using .corr() with spearman and pearson methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7f697-5f2a-41b5-9cbe-27ae8c1212f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.corr(method='spearman')[target_col].abs().sort_values()  # Spearman correlation for non-normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc233c-9351-4484-8b90-1fcb77c8108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.corr()[target_col].abs().sort_values() # Pearson is the default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26963e94-ca20-4e87-8267-fd73db984057",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "Creating new features in data science is an essential process that involves generating synthetic attributes from existing data. This process aims to extract additional information from the existing dataset, which can help improve the performance of machine learning models. By creating new features, data scientists can capture complex relationships and patterns that may be overlooked with only the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86769de1-3cda-471c-b69f-538f259f1870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fceaca1-8cc2-4152-ad56-57e35f275e22",
   "metadata": {},
   "source": [
    "# Regression modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06de56-4491-46ee-aefe-af18fdba0dbb",
   "metadata": {},
   "source": [
    "**Regression Modelling in Python with Scikit-learn**\n",
    "\n",
    "In this section, we will explore regression modelling using Python and the popular machine learning library, Scikit-learn. Regression is a supervised learning task that aims to model the relationship between input variables (features) and a continuous output variable (target).\n",
    "\n",
    "Scikit-learn provides a wide range of regression algorithms, including linear regression, random forests, catboost, and XGBoost. We will cover the basics of each algorithm and demonstrate how to implement them using Scikit-learn.\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "Linear regression is a simple yet powerful regression algorithm that models the relationship between features and the target as a linear function. We will discuss the assumptions of linear regression, how to train a model, and how to evaluate its performance using the root mean squared error (RMSE).\n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "Random forests are an ensemble learning method that combines multiple decision trees to improve prediction accuracy and reduce overfitting. Each tree in the forest is trained on a random subset of the data, and the final prediction is made by averaging the predictions of all the trees. Random forests are particularly useful for handling complex relationships and interactions between features, and they are also robust to outliers and noise in the data. We will demonstrate how to use random forests to model complex relationships and how to tune hyperparameters such as the number of trees and the maximum depth of the trees.\n",
    "\n",
    "**CatBoost**\n",
    "\n",
    "CatBoost is a gradient boosting algorithm that is known for its speed and accuracy. It uses a novel algorithm called \"ordinal encoding\" to handle categorical variables, which allows it to handle large numbers of categories efficiently. However, CatBoost can also be used for regression tasks that do not involve categorical data. We will demonstrate how to use CatBoost to model complex relationships and how to tune hyperparameters such as the learning rate and the number of iterations.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "XGBoost is a gradient boosting algorithm that is known for its speed and accuracy in regression tasks. It uses a novel algorithm called \"tree boosting\" to combine multiple decision trees, which allows it to handle complex relationships and interactions between features. We will demonstrate how to use XGBoost to model complex relationships and how to tune hyperparameters such as the learning rate, the number of trees, and the maximum depth of the trees.\n",
    "\n",
    "**Model Selection and Hyperparameter Tuning**\n",
    "\n",
    "In addition to the regression algorithms themselves, Scikit-learn provides tools for model selection and hyperparameter tuning. We will discuss the importance of model selection and hyperparameter tuning, and demonstrate how to use Scikit-learn's GridSearchCV and RandomizedSearchCV classes to find the best set of hyperparameters for a given regression algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a062de-8b49-41d4-92da-eaca6509eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692d26d-d9e3-4c77-aada-3b535ae444ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37213a7-4a75-447f-84a4-c4573129c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb653b46-04cf-4e43-8bb5-4e09dd6d80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "from numpy import absolute\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178a299-36cf-47ec-beff-030fe40b3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f92de-4623-4250-aed8-a2ae8011503b",
   "metadata": {},
   "source": [
    "## Separate training and test data from df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ec966-6448-47a3-a05d-7da6392a7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y dataframes\n",
    "\n",
    "target_column = 'metastatic_diagnosis_period'\n",
    "\n",
    "X = df_train.drop(target_column, axis=1)\n",
    "y = df_train[target_column]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30b7be-be61-4d9d-923c-c5cf16dd0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b802731-3e8d-4127-8bf7-75816785edc4",
   "metadata": {},
   "source": [
    "## Create train/test splits\n",
    "\n",
    "**train_test_split** is a common method for splitting data into training and testing sets. However, it does not handle class imbalance well and may result in uneven class distributions in the training and testing sets.\n",
    "\n",
    "**StratifiedShuffleSplit** is a cross-validation method that can be used when the target variable has a significant class imbalance. It randomly divides the data into training and testing sets, ensuring that the proportions of classes in both sets remain the same as those in the original data. This is useful when dealing with data where one class represents a minority or outlier.\n",
    "\n",
    "Below we will demonstrate how to use each approach. **You will only use one or the other, not both.**\n",
    "\n",
    "Let's try using train_test_split first, then come back and try stratified_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea59e33-225c-4562-901b-b2720815a58e",
   "metadata": {},
   "source": [
    "### train_test_split\n",
    "\n",
    "Use this or StratifiedShuffleSplit, not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e6391-ebcd-4d9f-8802-f22becded5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits using train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74728de7-d658-4b35-a0c9-aea859541c01",
   "metadata": {},
   "source": [
    "### StratifiedShuffleSplit\n",
    "\n",
    "Use this or train_test_split, not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbae77-b960-4dc1-bfed-a1e4d065fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(df, column_name, row_idx=None):\n",
    "    columns = df.columns.values.tolist()\n",
    "    columns.remove(column_name)\n",
    "    if row_idx is None:\n",
    "        return df[columns], df[column_name]\n",
    "    else:\n",
    "        return df[columns].iloc[row_idx], df[column_name].iloc[row_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97913d81-d209-411e-97b9-325437a6428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_test_split(df):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "    train_idx, test_idx = next(sss.split(*split_X_y(df, target_column)))\n",
    "    X_train, y_train = split_X_y(df, target_column, train_idx)\n",
    "    X_test, y_test = split_X_y(df, target_column, test_idx)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41132717-fbfc-44f4-9618-80b63f52ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = stratified_train_test_split(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af07c6-9d83-4acd-aa49-732d07fb92d8",
   "metadata": {},
   "source": [
    "## Function to predict on df_test data and create csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a5e9b-7e13-4c76-a04d-a885b83f4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model, df_test):\n",
    "    y_pred = model.predict(df_test)\n",
    "    df_test['metastatic_diagnosis_period'] = y_pred.tolist()\n",
    "    answers = df_test['metastatic_diagnosis_period']\n",
    "    answers.to_csv(\"output/answers.csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2ab7e-ae06-46db-ba3b-b42d4dc5b246",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "#### - Linear regression: Guessing a continuous value using a straight line based on features. Easy to understand!\n",
    "#### - Strengths: Easy to interpret, works fast, good starting point for many problems.\n",
    "#### - Weaknesses: Only works for straight line relationships, dislikes outliers.\n",
    "#### - Used for: Predicting stuff in finance, science, and machine learning! (e.g. house prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ad921-3166-4cd8-a44f-c300d8b507a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a69e91-57cd-4a3d-9c05-1dd77136fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b1ffc-c414-437f-b1f4-4511955d7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using RMSE\n",
    "rmse = np.sqrt(np.mean((y_test - model.predict(X_test)) ** 2))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835f6cb-0cc0-4233-9607-3932a6b1eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, model.predict(X_test), label=\"Predictions\", color=\"blue\")\n",
    "plt.plot(y_test, y_test, label=\"Actual\", color=\"red\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "title = \"Actual vs. Predicted Values (RMSE: {:.2f})\".format(rmse)\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE:\", rmse)  # Print RMSE for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005b20e-62e2-4536-81df-f786f54a2923",
   "metadata": {},
   "source": [
    "### Predict on test data and generate csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75373611-c4a5-4b37-864d-377af05c4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_test_data(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afccb22-34a7-4cf7-940b-211a26a74573",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "#### - Ensemble method: Random Forest combines multiple decision trees, reducing variance and improving overall accuracy.\n",
    "#### - Randomization: During training, each tree considers a random subset of features at each split point, preventing overfitting.\n",
    "#### - Out-of-bag error: Random Forest provides an estimate of prediction error for unseen data using out-of-bag samples (data points not used to train a specific tree).\n",
    "#### - Feature importance: Random Forest calculates the importance of each feature based on how much it contributes to the splits in the trees, aiding in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbb00d-75ae-4bd5-8f71-1ffe092b5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=500, max_features = 'sqrt', max_depth = 8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb520a-3d16-4133-9233-43e8938dcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, model.predict(X_test), label=\"Predictions\", color=\"blue\")\n",
    "plt.plot(y_test, y_test, label=\"Actual\", color=\"red\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "title = \"Actual vs. Predicted Values (RMSE: {:.2f})\".format(rmse)\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.show()\n",
    "plt.savefig(\"./RandomForest_actual_vs_predicted1.png\")\n",
    "\n",
    "\n",
    "print(\"RMSE:\", rmse)  # Print RMSE for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595c76f-8825-4f23-a427-686a8e0fc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "   'n_estimators': [100, 200, 500],\n",
    "   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   'max_depth' : [4,5,6,7,8]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da957e74-25a5-477c-b440-b2c5eacb4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=500, max_features = 'sqrt', max_depth = 8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcae62-e0bb-46d8-bb7f-37458f3e2f2a",
   "metadata": {},
   "source": [
    "### Predict on test data and generate csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601b79a-bbaa-4c66-bdd7-bf1d41fa21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_test_data(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee29772-7b89-4499-9d52-c240be9f76f0",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost is a gradient boosting algorithm that is known for its speed and accuracy in regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776480e9-d026-4b54-a9dd-831063062e33",
   "metadata": {},
   "source": [
    "#### - Gradient Boosting: XGBoost follows a gradient boosting approach, where each tree learns from the errors of the previous one, leading to a more optimized model.\n",
    "#### - Regularization: It incorporates L1 and L2 regularization to penalize model complexity and prevent overfitting.\n",
    "#### - Parallelization: XGBoost is optimized for parallel and distributed computing, making it efficient for large datasets.\n",
    "#### - Early Stopping: XGBoost can implement early stopping, which halts training when the validation score doesn't improve for a certain number of iterations, preventing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fefda-a005-45f0-b3a8-1102a0e75f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f86e8-5ecc-45e4-a442-05686d72ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4aa01-c5ef-4b96-88be-c4f43268c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using cross validation\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145a4a6-9d7f-496d-8bd0-f3e74502a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-validation Mean Squared Error: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b099cf9-9537-4acd-9462-c9bc3bc73d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force scores to be positive\n",
    "scores = absolute(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff12dc7-41ea-4ace-a58b-f529af7614b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a06425-7b1d-48ec-a87f-ae982b9542be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(scores)\n",
    "\n",
    "print('Mean RMSE: %.3f' % (rmse.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eab00a-f55e-4725-b60c-e650c68d9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, model.predict(X_test), label=\"Predictions\", color=\"blue\")\n",
    "plt.plot(y_test, y_test, label=\"Actual\", color=\"red\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "title = \"Actual vs. Predicted Values (RMSE: {:.2f})\".format(rmse)\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.show()\n",
    "plt.savefig(\"./RandomForest_actual_vs_predicted1.png\")\n",
    "\n",
    "\n",
    "print(\"RMSE:\", rmse)  # Print RMSE for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e23386-2355-4211-a253-59c911044299",
   "metadata": {},
   "source": [
    "### Predict on test data and generate csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c2cdb-6d56-4b63-b443-333d16a5ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_test_data(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56163aa4-110b-4a76-99c3-ed8d36a9481b",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "CatBoost is a gradient boosting algorithm that is known for its speed and accuracy.\n",
    "\n",
    "#### - Ordered CatBoosting: CatBoost handles categorical features by treating them as ordered (if applicable) or using a sophisticated approach for unordered categories.\n",
    "#### - Leave-One-Out Ranking: CatBoost employs a leave-one-out ranking objective during training, focusing on improving the relative order of predictions for similar data points.\n",
    "#### - Symmetric Trees: CatBoost utilizes symmetric trees, which can be split from either left or right, potentially leading to more efficient training.\n",
    "#### - Feature Importance Scores: Similar to Random Forest, CatBoost provides feature importance scores to understand which features contribute most to the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ed4f7-a550-48ac-818e-fe344f731119",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here's an overview of what the code does:\n",
    "\n",
    "cb is a shorthand for the CatBoost module.\n",
    "Pool is a class in CatBoost that represents a dataset. It takes two arguments: the feature matrix (X_train and X_test) and the target vector \n",
    "(y_train and y_test). The two Pool objects are created using the feature matrices and target vectors. These objects will be used to train \n",
    "and evaluate the model.\n",
    "\n",
    "So, in summary, the code creates two Pool objects, which represent the training and testing datasets, respectively.\n",
    "'''\n",
    "\n",
    "train_dataset = cb.Pool(X_train, y_train) \n",
    "test_dataset = cb.Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1a244-d917-4067-b5fc-e31710ce2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CatBoost regression model using RMSE as the loss function\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631c3d3-4538-4dae-b3e2-a3a9604cc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This Python code snippet demonstrates how to use the GridSearchCV class from the scikit-learn library to perform hyperparameter tuning \n",
    "for a regression model. The GridSearchCV class takes a grid of hyperparameters and trains the model with different combinations of \n",
    "these hyperparameters.\n",
    "\n",
    "In this example, the grid contains four hyperparameters: iterations, learning_rate, depth, and l2_leaf_reg. The iterations hyperparameter \n",
    "controls the number of iterations the model will run for, the learning_rate hyperparameter controls the learning rate of the model, the \n",
    "depth hyperparameter controls the maximum depth of the trees in the model, and the l2_leaf_reg hyperparameter controls the regularization \n",
    "strength of the model.\n",
    "\n",
    "The GridSearchCV class then trains the model with different combinations of these hyperparameters and evaluates the performance of the \n",
    "model using the mean squared error metric. The best combination of hyperparameters is then selected based on the performance of the model.\n",
    "'''\n",
    "\n",
    "grid = {'iterations': [100, 150, 200],\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'depth': [2, 4, 6, 8],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3]}\n",
    "\n",
    "model.grid_search(grid, train_dataset, verbose=1)\n",
    "\n",
    "# Compare GridSearchCV results to CatBoost grid_search\n",
    "#grid_search = GridSearchCV(model, grid, cv=5, scoring='neg_mean_squared_error')\n",
    "#grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297b3fb-e07b-49bf-ae6f-5f8bd9bd80ed",
   "metadata": {},
   "source": [
    "Now that we have the best model from the grid search, we will apply it to our test dataset.\n",
    "\n",
    "The RMSE metric measures the average squared difference between the predicted values and the actual values. A lower RMSE indicates a better fit.\n",
    "\n",
    "The R-squared metric measures the proportion of the variance in the target variable that is explained by the model. An R-squared value of 1 indicates that the model explains all of the variance in the target variable, while a value of 0 indicates that the model does not explain any of the variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef1fe3-c543-4097-8b64-65eb13da2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The predict method is used to make predictions on the test dataset, and the results are stored in the pred variable. It is important \n",
    "to note that the predict method should only be used on a test dataset that has not been used for training the model. Using the predict \n",
    "method on a training dataset can lead to overfitting and poor generalizability of the model.\n",
    "\n",
    "The metrics RMSE and R2 are then calculated.\n",
    "'''\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('R2: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553363a-9575-4789-913c-41bcf3198f1f",
   "metadata": {},
   "source": [
    "### Predict on the real test data and create the csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2ee6c-5a13-4b9e-bf0e-a169df6ef090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_test_data(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71325a-2424-4745-9482-79519b3479d0",
   "metadata": {},
   "source": [
    "### Submit results to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b2afb-b41a-4480-9949-4580d262251b",
   "metadata": {},
   "source": [
    "### CatBoost feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ced27-268a-45e7-9a6c-b9e838e375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e987b2-33ce-4530-8ef5-d7f0f95de47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = model.feature_importances_.argsort()\n",
    "plt.barh(feature_names[sorted_feature_importance], \n",
    "        model.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel(\"CatBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d5ced-ba09-4c45-b70f-235fdc5bc1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
